{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e23afa-0504-4700-8b5f-d8b80e4c59e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl mlflow pandas scikit-learn==1.5.2 oracledb python-dotenv tensorflow scikeras xgboost lightgbm seaborn --proxy http://172.25.156.90:3128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5abed1-7f7a-4deb-a639-3f04f2b6488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_utils import connect_to_oracle, get_data_for_anomaly_type\n",
    "from pipeline_utils import create_pipelines, evaluate_pipeline, evaluate_pipeline_oodd, create_pipelines_for_probs, evaluate_pipeline_from_probs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('./src/oodd_detectors')\n",
    "sys.path.append('./src/preprocessors')\n",
    "from target_preprocessor import create_target_pipeline\n",
    "import mlflow\n",
    "from continuous_OODD import OODDContinuousModel\n",
    "from categorical_OODD import OODDCategoricalModel, OODDSmoothedCategoricalModel\n",
    "from counter_OODD import CountBasedClassifier, FallbackCountClassifier\n",
    "from integer_counter_OODD import ContinuousCountBasedClassifier, FallbackContinuousCountClassifier\n",
    "from plot_utils import plot_target_distribution\n",
    "import pandas as pd\n",
    "from plot_utils import plot_target_distribution\n",
    "from db_utils import get_data_for_anomaly_type\n",
    "# needs scikit-learn version 1.5.2 (default 1.6.1 throws 'super' object has no attribute '__sklearn_tags__'.\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "connection, cursor = connect_to_oracle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2c1e3-e7e8-4d66-ad6f-8dd7ec8f8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_type = \"TEMPERATURE\"\n",
    "raw_df, X_cols, y_col = get_data_for_anomaly_type(\n",
    "    cursor, anomaly_type, limit=3000000)\n",
    "plot_target_distribution(raw_df, 'TEMPERATURE')\n",
    "plot_target_distribution(raw_df, 'TEMP_TO')\n",
    "plot_target_distribution(raw_df, 'TEMP_FROM')\n",
    "plot_target_distribution(raw_df, 'HEATING_TYPE')\n",
    "# plot_target_distribution(raw_df, 'HEATING_NOTE')\n",
    "print(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb26bed-2f36-41ee-b8b3-97eed011c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "def count_none_and_complete_rows(\n",
    "    df: pd.DataFrame,\n",
    "    cols: List[str]\n",
    ") -> Tuple[pd.Series, int]:\n",
    "    \"\"\"\n",
    "    For the given DataFrame and list of columns:\n",
    "      - Returns a Series of % null (None/NaN) per column.\n",
    "      - Returns the % of rows with no nulls in those columns.\n",
    "    \"\"\"\n",
    "    # validate columns\n",
    "    missing = set(cols) - set(df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"Unknown columns: {missing!r}\")\n",
    "\n",
    "    # % null per column\n",
    "    null_pct = df[cols].isnull().mean() * 100\n",
    "\n",
    "    # % complete rows across those columns\n",
    "    complete_pct = df[cols].notnull().all(axis=1).mean() * 100\n",
    "\n",
    "    return null_pct, complete_pct\n",
    "\n",
    "null_counts, complete_row = count_none_and_complete_rows(raw_df,['TEMPERATURE','TEMP_TO','TEMP_FROM'])\n",
    "print(null_counts)\n",
    "print(complete_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ce27e-97cc-4ed1-81dd-0744ed4da7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15712977-b9b7-4ae0-9cf9-657f35ef9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "def most_common_values_pct(\n",
    "    df: pd.DataFrame,\n",
    "    cols: Optional[List[str]] = None,\n",
    "    top_n: int = 1\n",
    ") -> Dict[str, pd.Series]:\n",
    "    \"\"\"\n",
    "    For each specified column (or all if cols is None), \n",
    "    return its top_n most frequent values (including NaNs) \n",
    "    as percentages of the total rows.\n",
    "    \"\"\"\n",
    "    if cols is None:\n",
    "        cols = list(df.columns)\n",
    "    missing = set(cols) - set(df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"Unknown columns: {missing!r}\")\n",
    "\n",
    "    result: Dict[str, pd.Series] = {}\n",
    "    total = len(df)\n",
    "    for col in cols:\n",
    "        pct = (\n",
    "            df[col]\n",
    "            .value_counts(dropna=False, normalize=True)\n",
    "            .mul(100)\n",
    "            .head(top_n)\n",
    "        )\n",
    "        result[col] = pct\n",
    "    return result\n",
    "top_pct = most_common_values_pct(raw_df, top_n=4)\n",
    "for col, series in top_pct.items():\n",
    "    print(f\"Column {col!r}:\")\n",
    "    print(series.round(2))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066146a7-b446-4de6-b059-9d7759bf9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_type = \"HEATING_TYPE\"\n",
    "bht_df, X_cols, y_col = get_data_for_anomaly_type(\n",
    "    cursor, anomaly_type, limit=100000000)\n",
    "plot_target_distribution(bht_df, y_col, \"Hea\")\n",
    "bht_df[y_col] = bht_df[y_col].map(\n",
    "                {None: 0.0, ' ': 0.0, 'X': 1.0}).fillna(bht_df[y_col])\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "bht_df[y_col] = le.fit_transform(bht_df[y_col])\n",
    "plot_target_distribution(bht_df, y_col, \"Customs number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a8594-fae7-4f58-b92a-289df84dc2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "def pct_blank_columns(\n",
    "    df: pd.DataFrame,\n",
    "    cols: List[str]\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    For the given DataFrame and list of columns, returns:\n",
    "      - percent_all_blank: % of rows where ALL specified cols are None or empty string.\n",
    "      - percent_any_blank: % of rows where ANY specified col is None or empty string.\n",
    "    \"\"\"\n",
    "    missing = set(cols) - set(df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"Unknown columns: {missing!r}\")\n",
    "\n",
    "    stripped = df[cols].astype(str).apply(lambda s: s.str.strip() == \"\")\n",
    "\n",
    "\n",
    "    mask = df[cols].isnull() | (df[cols] == \"\") | (df[cols] == \" \") | stripped\n",
    "    percent_all_blank = mask.all(axis=1).mean() * 100\n",
    "    percent_any_blank = mask.any(axis=1).mean() * 100\n",
    "    return percent_all_blank, percent_any_blank\n",
    "\n",
    "all_pct, any_pct = pct_blank_columns(raw_df, ['TEMPERATURE','TEMP_TO','TEMP_FROM'])\n",
    "print(f\"All blank: {all_pct:.2f}%\")  # e.g. 50.0%\n",
    "print(f\"Any blank: {any_pct:.2f}%\")  # e.g. 75.0%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc15745-36c9-41f9-90e8-931c0f2b887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_type = \"BHT\"\n",
    "bht_df, X_cols, y_col = get_data_for_anomaly_type(\n",
    "    cursor, anomaly_type, limit=100000000)\n",
    "plot_target_distribution(bht_df, y_col, \"Customs number raw\")\n",
    "bht_df[y_col] = bht_df[y_col].map(\n",
    "                {None: 0.0, ' ': 0.0, 'X': 1.0}).fillna(bht_df[y_col])\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "bht_df[y_col] = le.fit_transform(bht_df[y_col])\n",
    "plot_target_distribution(bht_df, y_col, \"Customs number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04492d-c214-4f6b-b98f-ecdd4798bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_type = \"HEATING_TYPE\"\n",
    "bht_df, X_cols, y_col = get_data_for_anomaly_type(\n",
    "    cursor, anomaly_type, limit=100000000)\n",
    "plot_target_distribution(bht_df, y_col, \"Heating Type raw\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "bht_df[y_col] = le.fit_transform(bht_df[y_col])\n",
    "plot_target_distribution(bht_df, y_col, \"Heating Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331b2c8-e0e4-4e88-99aa-d0f4e8dd6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_type = \"IM_TK_HEAT\"\n",
    "df, X_cols, y_col = get_data_for_anomaly_type(\n",
    "    cursor, anomaly_type, limit=100000000)\n",
    "plot_target_distribution(df, y_col, \"Has heating raw\")\n",
    "df[y_col] = df[y_col].map(\n",
    "                {None: 0.0, ' ': 0.0, 'X': 1.0}).fillna(df[y_col])\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[y_col] = le.fit_transform(df[y_col])\n",
    "plot_target_distribution(df, y_col, \"Has heating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef33f2-8837-4880-842a-1c4834a0875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_type = \"TEMPERATURE\"\n",
    "df, X_cols, y_col = get_data_for_anomaly_type(\n",
    "    cursor, anomaly_type, limit=100000000)\n",
    "plot_target_distribution(df, y_col, \"TEMPERATURE raw\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[y_col] = le.fit_transform(df[y_col])\n",
    "plot_target_distribution(df, y_col, \"TEMPERATURE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad9a1f-8bcc-448a-8d3f-a72665391fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_type = \"T_CH_TYP_NA\"\n",
    "df, X_cols, y_col = get_data_for_anomaly_type(\n",
    "    cursor, anomaly_type, limit=100000000)\n",
    "plot_target_distribution(df, y_col, \"Chassis type import raw\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[y_col] = le.fit_transform(df[y_col])\n",
    "plot_target_distribution(df, y_col, \"Chassis type import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc157c76-a99d-4d47-97d0-d0afa33dfafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_type = \"T_CH_TYP_VY\"\n",
    "df, X_cols, y_col = get_data_for_anomaly_type(\n",
    "    cursor, anomaly_type, limit=100000000)\n",
    "plot_target_distribution(df, y_col, \"Chassis type export raw\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[y_col] = le.fit_transform(df[y_col])\n",
    "plot_target_distribution(df, y_col, \"Chassis type export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a0630-a107-47d8-90f8-a0b2c4cd4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_type = \"EX_SP_REF\"\n",
    "df, X_cols, y_col = get_data_for_anomaly_type(\n",
    "    cursor, anomaly_type, limit=100000000)\n",
    "plot_target_distribution(df, y_col, \"Additional reference export raw\")\n",
    "df[y_col] = df[y_col].astype(str)\n",
    "df[y_col] = df[y_col].apply(\n",
    "    lambda x: 0 if pd.isna(x) or str(x).strip() == '' else 1)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[y_col] = le.fit_transform(df[y_col])\n",
    "plot_target_distribution(df, y_col, \"Additional reference export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7da59f-55bb-494a-bf3b-b8280ee55fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_type = \"IM_SP_REF\"\n",
    "df, X_cols, y_col = get_data_for_anomaly_type(\n",
    "    cursor, anomaly_type, limit=100000000)\n",
    "plot_target_distribution(df, y_col, \"Additional reference import raw\")\n",
    "df[y_col] = df[y_col].astype(str)\n",
    "df[y_col] = df[y_col].apply(\n",
    "    lambda x: 0 if pd.isna(x) or str(x).strip() == '' else 1)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[y_col] = le.fit_transform(df[y_col])\n",
    "plot_target_distribution(df, y_col, \"Additional reference import\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
