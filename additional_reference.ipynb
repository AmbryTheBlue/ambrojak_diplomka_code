{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895a644-0317-434f-897e-5aabb79df115",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl mlflow pandas scikit-learn==1.5.2 oracledb python-dotenv tensorflow scikeras xgboost lightgbm seaborn --proxy http://172.25.156.90:3128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5a9ad-c2ad-433a-8d76-891a08eef49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_utils import connect_to_oracle, get_data_for_anomaly_type\n",
    "from pipeline_utils import create_pipelines, evaluate_pipeline, evaluate_pipeline_oodd, create_pipelines_for_probs, evaluate_pipeline_from_probs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('./src/oodd_detectors')\n",
    "sys.path.append('./src/preprocessors')\n",
    "import mlflow\n",
    "from continuous_OODD import OODDContinuousModel\n",
    "from categorical_OODD import OODDCategoricalModel, OODDSmoothedCategoricalModel\n",
    "from counter_OODD import CountBasedClassifier, FallbackCountClassifier\n",
    "from target_preprocessor import create_target_pipeline\n",
    "from plot_utils import compare_models_from_components\n",
    "from plot_utils import plot_target_distribution, print_latex_table\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "# needs scikit-learn version 1.5.2 (default 1.6.1 throws 'super' object has no attribute '__sklearn_tags__'.\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "connection, cursor = connect_to_oracle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2062d4-8d47-4af7-b34d-de2811b8ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, X_cols, y_col = get_data_for_anomaly_type(\n",
    "    cursor, 'IM_SP_REF_WITHOUT_PR', limit=200000)\n",
    "# plot_target_distribution(df, y_col)\n",
    "y_pipe = create_target_pipeline(y_col, 'IM_SP_REF_WITHOUT_PR')\n",
    "df[y_col] = y_pipe.fit_transform(df[y_col])\n",
    "print(X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05240d-8b86-41a9-a69c-60bd96369596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, X_cols, y_col = get_data_for_anomaly_type(cursor, 'HEATING_TYPE', limit=200000)\n",
    "model_dict = {}\n",
    "X_train, X_test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"\\nFBOD:\")\n",
    "TP, FP, TN, FN = evaluate_pipeline_oodd(CountBasedClassifier(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical')\n",
    "model_dict[\"FBOD\"] = (TP, FP, TN, FN)\n",
    "print(\"\\nFBODBackOff:\")\n",
    "TP, FP, TN, FN = evaluate_pipeline_oodd(FallbackCountClassifier(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical')\n",
    "model_dict[\"FBODBackOff\"] = (TP, FP, TN, FN)\n",
    "from text_preprocessor import TextPreprocessor\n",
    "new_df = TextPreprocessor(X_cols).fit_transform(df)\n",
    "X_train, X_test = train_test_split(new_df, test_size=0.1, random_state=42)\n",
    "print(\"\\nFBOD:\")\n",
    "TP, FP, TN, FN = evaluate_pipeline_oodd(CountBasedClassifier(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical')\n",
    "model_dict[\"FBOD-preprocess\"] = (TP, FP, TN, FN)\n",
    "print(\"\\nFBODBackOff:\")\n",
    "TP, FP, TN, FN = evaluate_pipeline_oodd(FallbackCountClassifier(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical')\n",
    "model_dict[\"FBODBackOff-preprocess\"] = (TP, FP, TN, FN)\n",
    "\n",
    "compare_models_from_components(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a873dd-ffec-4164-8ded-1b759b35319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dict = {}\n",
    "y = df[y_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.1, random_state=42)\n",
    "\n",
    "for pipeline in create_pipelines(X_cols):\n",
    "    name = 'MD:' + pipeline.steps[-1][0]\n",
    "    # Evaluate the pipeline\n",
    "    TP, FP, TN, FN  = evaluate_pipeline(pipeline, X_train, y_train,\n",
    "                      X_test, y_test, verbose=False)\n",
    "    model_dict[name] = (TP, FP, TN, FN)\n",
    "compare_models_from_components(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c25195-5883-41ed-b6af-cc29fd36f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dict = {}\n",
    "for pipeline in create_pipelines_for_probs(X_cols):\n",
    "    name = 'CBAD:' + pipeline.steps[-1][0]\n",
    "    print('\\n' + name)\n",
    "    TP, FP, TN, FN  = evaluate_pipeline_from_probs(pipeline, X_train, y_train,  X_test, y_test, threshold=0.5, target_col=y_col)\n",
    "    model_dict[name] = (TP, FP, TN, FN)\n",
    "compare_models_from_components(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de065c-ed5c-4aae-b83b-95c51f54ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latex_table(model_dict, \"Additional Reference Import\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
