{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895a644-0317-434f-897e-5aabb79df115",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl mlflow pandas scikit-learn==1.5.2 oracledb python-dotenv tensorflow scikeras xgboost lightgbm seaborn --proxy http://172.25.156.90:3128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5a9ad-c2ad-433a-8d76-891a08eef49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_utils import connect_to_oracle, get_data_for_anomaly_type\n",
    "from pipeline_utils import create_pipelines, evaluate_pipeline, evaluate_pipeline_oodd, create_pipelines_for_probs, evaluate_pipeline_from_probs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('./src/oodd_detectors')\n",
    "import mlflow\n",
    "from continuous_OODD import OODDContinuousModel\n",
    "from categorical_OODD import OODDCategoricalModel, OODDSmoothedCategoricalModel\n",
    "from counter_OODD import CountBasedClassifier, FallbackCountClassifier\n",
    "from plot_utils import compare_models_from_components\n",
    "from plot_utils import plot_target_distribution\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "# needs scikit-learn version 1.5.2 (default 1.6.1 throws 'super' object has no attribute '__sklearn_tags__'.\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "connection, cursor = connect_to_oracle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2062d4-8d47-4af7-b34d-de2811b8ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, X_cols, y_col = get_data_for_anomaly_type(\n",
    "    cursor, 'HEATING_TYPE_WITH_GOODS_WITH_CHASSIS', limit=200000)\n",
    "# plot_target_distribution(df, y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05240d-8b86-41a9-a69c-60bd96369596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, X_cols, y_col = get_data_for_anomaly_type(cursor, 'HEATING_TYPE', limit=200000)\n",
    "model_dict = {}\n",
    "X_train, X_test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "# print(\"\\nOODDContinuousModel:\")\n",
    "# TP, FP, TN, FN = evaluate_pipeline_oodd(OODDContinuousModel(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical3' )\n",
    "# model_dict[\"OODDContinuousModel\"] = (TP, FP, TN, FN)\n",
    "# print(\"\\nOODDCategoricalModel:\")\n",
    "# TP, FP, TN, FN = evaluate_pipeline_oodd(OODDCategoricalModel(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical3')\n",
    "# model_dict[\"OODDCategoricalModel\"] = (TP, FP, TN, FN)\n",
    "# print(\"\\nOODDSmoothedCategoricalModel:\")\n",
    "# TP, FP, TN, FN = evaluate_pipeline_oodd(OODDSmoothedCategoricalModel(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical3')\n",
    "# model_dict[\"OODDSmoothedCategoricalModel\"] = (TP, FP, TN, FN)\n",
    "print(\"\\nFBOD:\")\n",
    "TP, FP, TN, FN = evaluate_pipeline_oodd(CountBasedClassifier(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical3')\n",
    "model_dict[\"FBOD\"] = (TP, FP, TN, FN)\n",
    "print(\"\\nFBODBackOff:\")\n",
    "TP, FP, TN, FN = evaluate_pipeline_oodd(FallbackCountClassifier(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical3')\n",
    "model_dict[\"FBODBackOff\"] = (TP, FP, TN, FN)\n",
    "\n",
    "compare_models_from_components(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a873dd-ffec-4164-8ded-1b759b35319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dict = {}\n",
    "le = LabelEncoder()\n",
    "y = pd.Series(le.fit_transform(df[y_col]), index=df.index, name=y_col)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.1, random_state=42)\n",
    "\n",
    "for pipeline in create_pipelines(X_cols):\n",
    "    name = 'MD:' + pipeline.steps[-1][0]\n",
    "    # Evaluate the pipeline\n",
    "    TP, FP, TN, FN  = evaluate_pipeline(pipeline, X_train, y_train,\n",
    "                      X_test, y_test, verbose=False)\n",
    "    model_dict[name] = (TP, FP, TN, FN)\n",
    "compare_models_from_components(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c25195-5883-41ed-b6af-cc29fd36f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dict = {}\n",
    "for pipeline in create_pipelines_for_probs(X_cols):\n",
    "    name = 'CBAD:' + pipeline.steps[-1][0]\n",
    "    print('\\n' + name)\n",
    "    TP, FP, TN, FN  = evaluate_pipeline_from_probs(pipeline, X_train, y_train,  X_test, y_test, threshold=0.5, target_col=y_col)\n",
    "    model_dict[name] = (TP, FP, TN, FN)\n",
    "compare_models_from_components(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de065c-ed5c-4aae-b83b-95c51f54ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tahat(results: dict, name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Given a dict mapping model names to [TP, FP, TN, FN],\n",
    "    computes Accuracy, Recall, Precision, F1;\n",
    "    prints a TeX table of metrics;\n",
    "    returns a dict with all metrics per model.\n",
    "    \"\"\"\n",
    "    # 1) Compute metrics and print TeX table\n",
    "    metrics = {}\n",
    "    for model, (tp, fp, tn, fn) in results.items():\n",
    "        total    = tp + fp + tn + fn\n",
    "        accuracy  = (tp + tn) / total       if total else 0\n",
    "        recall    = tp / (tp + fn)          if (tp + fn) else 0\n",
    "        precision = tp / (tp + fp)          if (tp + fp) else 0\n",
    "        f1        = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "        # store\n",
    "        metrics[model] = {\n",
    "            'TP': tp, 'FP': fp, 'TN': tn, 'FN': fn,\n",
    "            'Accuracy': accuracy,\n",
    "            'Recall': recall,\n",
    "            'Precision': precision,\n",
    "            'F1': f1\n",
    "        }\n",
    "\n",
    "    print(r\"\\midinsert \\clabel[table\" + name.replace(' ','') + \"]{Model Copmarison\" + name +\"}\")\n",
    "    print(r\"\\ctable{l|rrrrrrr|r}{\")\n",
    "    print(r\"Model & TP & FP & TN & FN & Accuracy & Recall & Precision & F1 \\crli \\tskip4pt\")\n",
    "    # sort models by F1\n",
    "    for model, vals in sorted(metrics.items(), key=lambda item: item[1]['F1'], reverse=True):\n",
    "        tp = vals['TP']; fp = vals['FP']; tn = vals['TN']; fn = vals['FN']\n",
    "        \n",
    "        total = tp+fp+tn+fn\n",
    "        print(f\"{model} & {tp/total:.3f} & {fp/total:.3f} & {tn/total:.3f} & {fn/total:.3f} \"\n",
    "              f\"& {vals['Accuracy']:.3f} & {vals['Recall']:.3f} & {vals['Precision']:.3f} & {vals['F1']:.3f} \\\\cr\")\n",
    "    print(r\"}\")\n",
    "    print(r\"\\caption/t Performance metrics per model in \" + name + \" (sorted by F1)\")\n",
    "    print(r\"\\endinsert\")\n",
    "\n",
    "    return metrics\n",
    "tahat(model_dict, \"Heating Type Anomaly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0849e-5cde-4225-933e-d854de954775",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "X_train, X_test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "# print(\"\\nOODDContinuousModel:\")\n",
    "# TP, FP, TN, FN = evaluate_pipeline_oodd(OODDContinuousModel(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical3' )\n",
    "# model_dict[\"OODDContinuousModel\"] = (TP, FP, TN, FN)\n",
    "# print(\"\\nOODDCategoricalModel:\")\n",
    "# TP, FP, TN, FN = evaluate_pipeline_oodd(OODDCategoricalModel(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical3')\n",
    "# model_dict[\"OODDCategoricalModel\"] = (TP, FP, TN, FN)\n",
    "# print(\"\\nOODDSmoothedCategoricalModel:\")\n",
    "# TP, FP, TN, FN = evaluate_pipeline_oodd(OODDSmoothedCategoricalModel(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical3')\n",
    "# model_dict[\"OODDSmoothedCategoricalModel\"] = (TP, FP, TN, FN)\n",
    "print(\"\\nFBOD:\")\n",
    "TP, FP, TN, FN = evaluate_pipeline_oodd(CountBasedClassifier(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical')\n",
    "model_dict[\"FBOD\"] = (TP, FP, TN, FN)\n",
    "print(\"\\nFBODBackOff:\")\n",
    "TP, FP, TN, FN = evaluate_pipeline_oodd(FallbackCountClassifier(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical')\n",
    "model_dict[\"FBODBackOff\"] = (TP, FP, TN, FN)\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "def preprocess_text(text):\n",
    "    # Normalize and replace accented chars with ASCII equivalents\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    text = re.sub(r'\\s', ' ', text)\n",
    "    text = text.upper()\n",
    "    text = re.sub(r'[^A-Z0-9]', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "X_copy = X_train.copy()\n",
    "for col in X_cols:\n",
    "    X_copy[col] = X_copy[col].astype(str)\n",
    "    X_copy[col] = X_copy[col].apply(preprocess_text)\n",
    "X_train = X_copy\n",
    "\n",
    "X_copy = X_test.copy()\n",
    "for col in X_cols:\n",
    "    X_copy[col] = X_copy[col].astype(str)\n",
    "    X_copy[col] = X_copy[col].apply(preprocess_text)\n",
    "X_test = X_copy\n",
    "\n",
    "print(\"\\nFBOD:\")\n",
    "TP, FP, TN, FN = evaluate_pipeline_oodd(CountBasedClassifier(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical')\n",
    "model_dict[\"FBOD-preprocess\"] = (TP, FP, TN, FN)\n",
    "print(\"\\nFBODBackOff:\")\n",
    "TP, FP, TN, FN = evaluate_pipeline_oodd(FallbackCountClassifier(X_cols, y_col), X_train, X_test, target_col=y_col,type='categorical')\n",
    "model_dict[\"FBODBackOff-preprocess\"] = (TP, FP, TN, FN)\n",
    "\n",
    "from plot_utils import compare_models_from_components\n",
    "compare_models_from_components(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe0c1c5-6002-4a2c-926d-51744d589181",
   "metadata": {},
   "outputs": [],
   "source": [
    "tahat(model_dict,\"Compare preprocessing FBOD\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
